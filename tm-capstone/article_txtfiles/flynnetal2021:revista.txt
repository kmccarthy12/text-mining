The appearance of coherence: Using cohesive properties of readers’ constructed responses to predict individual differences. 

ABSTRACT

Successful text comprehension requires readers to engage in a number of coherence-building processes. This study examined how analyzing the cohesion of students’ constructed responses can be used to evaluate these coherence-building processes and the extent to which they vary across readers’ individual differences and across types of texts. We posed two primary research questions: 1) Can we predict individual differences in working memory and reading skill based on the cohesion of students’ constructed responses to text? 2) Do the relations between individual differences and cohesion vary as a function of genre? Participants (n = 119) generated constructed responses while reading history and science texts and completed reading skill and working memory assessments. The current study leveraged natural language processing (NLP) techniques to analyze the cohesion of readers’ constructed responses, using cohesion as a proxy for assessing the coherence of their mental representations of the texts. Cohesion was measured at the sentence, paragraph, and synonym levels. Machine learning models showed that linguistic indices related to cohesion were significant predictors of both working memory and reading skill. Additional quantitative and qualitative inspection revealed that the relations between individual differences and coherence-building processes varied depending on the text’s genre. These findings indicate that the interaction between genre and individual differences may be used to model coherence-building processes during reading. This study has important implications for the realm of educational technology such as in the implementation of stealth assessments to predict students’ cognitive abilities.

Key Words: Reading comprehension; individual differences; think-aloud methods; genre effects; coherence-building processes

INTRODUCTION

Successful text comprehension occurs when a reader has constructed a ‘coherent’ and meaningful mental representation of a text (McNamara & Magliano, 2009). Coherence, or the interconnectedness of this mental representation, involves establishing how explicitly conveyed content is semantically related in the mental representation. These semantic relationships are established via explicit content in the text in combination with inference generation on the part of the reader (Graesser, Singer & Trabasso, 1994). In the context of reading simple narrative texts, inferences may be heavily supported by implicit processes that do not require conscious effortful processing (Myers & O’Brien, 1998). However, in the context of challenging texts or texts in which readers have relatively little relevant prior knowledge, establishing these inferences may require substantial effort (McNamara, 2004; McNamara & Magliano, 2009). As such, there is considerable research on individual differences that are associated with ‘coherence-building’ (e.g., Whitney, Ritchie & Clark, 1991; Magliano & Millis, 2003; Klauda & Guthrie, 2008; Magliano, Higgs, Santuzzi, Tonks, O' Reilly, Sabatini, Feller, Kopatich, Ray & Parker, 2020).

Text comprehension is supported by cognitive skills that are specific to reading as well as those that can be construed as relatively domain-general (Kopatich, Magliano, Millis, Parker & Ray, 2019). Indeed, prior work shows that reading skill (i.e., performance on standardized tests of comprehension proficiency) is a predictor of comprehension such that skilled readers are more likely to engage in increased coherence-building processes during reading as compared to less skilled readers (Magliano & Millis, 2003; Klauda & Guthrie, 2008). Additionally, working memory capacity is a relative domain-general aspect of cognition that may support the ability to develop coherence during reading (Turner & Engle, 1989). In the present study, we explored the extent to which a novel and informative approach to assessing coherence-building is predictive of individual differences in reading skill and working memory capacity.

To this end, we examined coherence-building by analyzing students’ constructed responses that they produced as they read. ‘Constructed responses’ such as think-aloud protocols are online measures that can provide a direct window into coherence-building processes during reading (Trabasso & Magliano, 1996; Magliano & Millis, 2003). Think-aloud procedures typically involve readers being intermittently interrupted and prompted to report their thoughts as they come to mind (Ericsson & Simon, 1980; Pressley & Afflerbach, 1995). One way of leveraging these constructed responses is to score their quality in terms of the extent to which the reader appears to be constructing a more global understanding of the text (Coté & Goldman, 1999). The quality of constructed responses has been associated with readers’ comprehension of the target texts (McCarthy et al., 2020) as well as various individual differences in reading skill (Magliano & Millis, 2003; Coiro, 2011), prior knowledge (Pressley, Wood, Woloshyn, Martin, King & Menke, 1992), and working memory (Bohn-Gettler & Kendeou, 2014; Whitney et al.,1991). An alternative approach to leveraging constructed responses is by analyzing their linguistic properties via natural language processing (NLP) methodologies (Magliano & Graesser, 2012; McNamara, Allen, McCarthy & Baylan, 2018 ). We used an NLP approach in the current study to assess the extent that measures of coherence-building as revealed by constructed responses are predictive of individual differences in reading skill and working memory. The study uses an approach developed by Allen, Snow and McNamara (2015), Allen, Jacovina and McNamara (2016) that uses the ‘cohesion’ of students’ constructed responses to model individual differences. More specifically, this study examines if linguistic features of constructed responses are predictive of individual differences and the extent to which these relations vary across genres.

We conducted this study in honor of Giovanni Parodi Sweis, a leader, mentor, and generous colleague to innumerable students and researchers seeking to better understand language, comprehension, and literacy. This study embodies Giovanni by combining multiple methods germane to computational linguistics, corpus linguistics, and discourse analyses to further our understanding of individual differences in students’ ability to comprehend different text genres. With heavy hearts, we remember Giovanni fondly, as a generous and kind mentor, and friend.

1. Individual differences in reading comprehension

The current study focuses on two individual differences: reading skill and working memory. These individual differences have been linked to performance in a variety of reading comprehension contexts, such as multiple-document comprehension (Barzilai & Strømsø, 2018; Stadtler, Bromme & Rouet, 2018), science comprehension (Allen, Snow, Crossley, Jackson & McNamara, 2014; McNamara, Graesser, McCarthy & Cai, 2014; O’Reilly, Sinclair & McNamara, 2004), and narrative text processing (Bower & Morrow, 1990; van den Broek, 1994).

Reading skill refers to a number of specific cognitive skills that are associated with successful reading processes, ranging from the decoding of individual words (Perfetti, 1985) to syntactic knowledge and the skills necessary for making connections with prior knowledge (Gernsbacher, Varner & Faust, 1990; Hannon & Daneman, 2001). This ability to generate connections amongst items contained in the text, as well as with prior knowledge is critical for deep comprehension (Oakhill & Yuill, 1986; Hannon & Daneman, 2001). Reading skill is correlated with increased comprehension of texts and can be significantly impacted based on the properties of the text being read (Ozuru, Dempsey & McNamara, 2009). Importantly, reading skill can be improved through training which helps readers to generate stronger connections with the text and consequently build a more coherent representation during reading (e.g., McNamara, 2004).

In addition to reading-specific skills, differences in working memory capacity may also affect how readers process and store information from texts (Daneman & Carpenter, 1980). Performance on working memory tasks is positively correlated with measures of text comprehension. Researchers have argued that readers with lower performance on working memory capacity tasks may struggle to integrate texts into their mental representations due to weaker attention-control mechanisms (Daneman & Carpenter, 1980; Kane & McVay, 2012). For example, working memory has been found to be a necessary component in integrative computations of pronominal referents (Daneman & Carpenter, 1980). Another study found that children with higher working memory capacities performed better on reading comprehension tasks involving surface-level and deep comprehension questions (Borella & de Ribaupierre, 2014). Thus, individuals who perform well on working memory tasks may be better equipped to comprehend texts, both at shallow and deep levels, by having prior information more readily accessible. This may, in turn, make it easier for readers to connect concepts and ideas across a text, aiding in the construction of coherent mental representations (Daneman & Carpenter, 1980).

Whitney et al. (1991) provided some evidence that individual differences in working memory capacity are related to coherence-building. They had college students think aloud while reading narrative texts. They also measured individual differences in working memory capacity with a span task. Lower span readers tended to produce thoughts that focused on establishing local coherence, whereas higher span readers tended to produce thoughts that emphasized global coherence until they got to the end of the story where they produced statements that reflected more specific interpretations of the narrative events. Whitney et al. argued that individual differences in reading span led to readers differentially trading off between establishing local (between immediate sentences) and global (between distally related sentence) coherence.

2. Assessing the cohesion of constructed responses

Although there are multiple linguistic features that can be used to characterize constructed responses, the cohesion of these responses is particularly relevant in providing insight into the coherence of the readers’ mental representation of the text. ‘Cohesion’ refers to the explicit cues that establish connections amongst text content (McNamara et al., 2014). The cohesion of constructed responses can be assessed in terms of overlap between utterances, such as content words (e.g., nouns, verbs). Highly connected ideas about the text correspond to higher coherence, and in turn, deeper levels of comprehension (Allen et al., 2016). As such, the cohesion of constructed responses generated during reading has recently been proposed as a proxy for the coherence of the readers’ mental representations (Allen et al., 2015, 2016). For this reason, the cohesion of constructed responses produced during the coherence-building process should be influenced by individual differences in the same way that it affects the coherence of readers’ mental representations of text.

Allen et al. (2015) developed a model to predict performance on the Gates-MacGinitie Reading Test (MacGinitie, MacGinitie, Maria & Dreyer, 2000) based on the linguistic features of students’ constructed responses to texts. In this study, participants were asked to produce self-explanations at key points while reading a science text. NLP techniques were then used to analyze these self-explanations along a number of linguistic dimensions (e.g., word, sentence, and cohesion). These linguistic indices were then used in a linear model to predict performance on the Gates-MacGinitie assessment. Skilled readers were more likely to generate self-explanations containing greater semantically overlap and more explicit connections between their self-explanations. This study provided preliminary evidence that reading comprehension skills can be modeled based on the linguistic properties of readers’ constructed responses. Allen et al. (2016) extended this work by examining how the cohesion of constructed responses varied across instructions to engage in different reading strategies (i.e., paraphrasing, self-explanations). When readers were prompted with self-explanation instructions, they produced more diverse language and global connectives in their constructed responses (Allen et al., 2016). This provides further evidence that the cohesion of constructed responses can serve as a proxy for coherence-building processes.

3. Genre effects on comprehension

Beyond individual differences, comprehension can also be impacted by the nature of the text being read. For example, recent meta-analyses have shown that readers process, understand, and recall narrative texts differently than expository texts (Clinton, Taylor, Bajpayee, Davison, Carlson & Seipel, 2020; Mar, Li, Nguyen & Ta, 2021).

While the nature of genre is debated, it is generally agreed upon that different text genres have different purposes, are marked by different linguistic features, and can be reliably distinguished by readers. For instance, social studies and science texts have more challenging words and sentence structures compared to narrative texts (McNamara, Graesser & Louwerse, 2012). These aspects of text difficulty further translate to differences in text cohesion. For example, narratives tend to contain less referential cohesion, but more connectives compared to science texts. This linguistic variation drives differences in the coherence-building processes that afford comprehension (McNamara et al., 2012).

These features of texts also have top-down effects on individuals’ coherence-building processes and subsequent comprehension (McNamara et al., 2012; Zwaan, 1994). For example, readers’ genre expectations have been shown to affect the cognitive top-down processes that occur while they construct and update their mental representations during reading (Kintsch, 1992; Parodi, 2014; Schmitz, Gräesel & Rothstein, 2017). Zwaan (1994) asked participants to read a text with the expectation that it was either a literary story or a news story. Although the text was identical in both conditions, participants reading from the literary perspective had longer reading times and better memory for surface-level information but had a weaker memory for situational information compared to those reading from the news perspective. Genre has also been found to be an important factor in how well readers integrate text content with prior knowledge (Wolfe & Mienko, 2007). This, and similar studies, provide evidence that individuals’ knowledge and expectations of genres can influence their processing and ultimate comprehension of texts (Rozimela, 2014).

Although the majority of work in genre differences has focused on narrative versus expository texts, work in genre studies and disciplinary literacies suggest that coherence-building processes vary across more nuanced genre categories. Indeed, Parodi (2010, 2014, 2015) identified key differences between the genres of social sciences/humanities and basic sciences in academic discourses. These differences can be distilled into three major components: 1) the ways in which pedagogic devices are articulated, 2) the types of methodological procedures being transferred, and 3) the extent to which the knowledge expressed is either abstract or concrete. Researchers interested in discipline-specific comprehension challenges have further identified that science and history texts tend to be written in ways that are inconsiderate of students’ knowledge and reading skills (e.g., Moje & Speyer, 2008), but also that each type of text presents specific challenges in establishing and maintaining coherence (Beck & McKeown, 1988; Goldman & Bisanz, 2002). However, few studies have explicitly examined these coherence-building and processing differences side-by-side.

Importantly, an abundance of work in the text comprehension literature has studied these genres in relatively isolated contexts. For example, narrative texts are rarely measured in the same experimental contexts and studies as expository texts; science and history texts are generally studied in different contexts and by different researchers. Also, the methodologies and assessments that are used to examine the various genres tend to vary widely. It is therefore an open question as to whether and how these individual differences and coherence-building processes interact differently across genres. Thus, a novel contribution of the current study is our examination of whether individual differences and genre interact to impact coherence-building processes during reading, as measured by cohesion dimensions.

4. Current study

The current study assesses the coherence of readers’ mental representations during the reading process using the cohesive properties of their constructed responses. Specifically, we examined the cohesion of responses constructed by participants while they read texts of different genres (i.e., history, science) from an archival data set (Magliano, Durik & Holt, 2011). We posed two primary research questions: 1) Can we predict individual differences in working memory and reading skill based on the cohesion of students’ constructed responses to text? 2) Do the relations between individual differences and cohesion vary as a function of genre?

5. METHOD

5.1. Participants

Participants from this archival data (Magliano et al., 2011) set were undergraduate students (n = 119) enrolled in an introduction to psychology course from a large Midwestern University who received course credit for their participation. Of these participants, 45% were female. In addition, 55% were Caucasian, 17% were African American, 7% were Hispanic, 4% were Asian American, 1% were Native American, and 16% reported that their ethnicity did not fall into any of the above options provided. We include ethnicity in our description of participants for the purposes of replication and generalization across different populations in extensions of this work. Three participants did not complete the working memory task and so they were not included in any working memory analyses.

5.2. Materials

5.2.1. Text passages

Participants were randomly assigned to read one of two history texts (i.e., economic causes of the Civil War or garment worker labor strikes) and one of two science texts (i.e., erosion or geographic isolation and the evolution of species). The texts were relatively matched for length (299-390 words) and readability (Flesch-Kincaid Grade Level from 9.2-11.5). Participants each read only one history text and one science (see Appendix for example passages from the text) to prevent fatigue effects.

5.2.2. Reading strategy assessment tool (RSAT)

The protocols were collected in the context of the Reading Strategy Assessment Tool (RSAT), which is an online data collection tool for collecting constructed responses while reading texts (Magliano et al., 2011). RSAT contains instruction and practice for producing constructed responses. The instructions and practice were delivered by the experimenter and were presented on paper. Participants were instructed to ‘think aloud’ in response to the prompts. They were told that thinking aloud involves producing whatever comes to mind in terms of their understanding of the sentence that was just read and in the context of the larger text. The instructions specify that participants should avoid restricting their response to short phrases (e.g., ‘OK, makes sense’) and making comments for humorous purposes. Practice consisted of reading a short 5-sentence text on the expansion of railroads in the American West during the middle 1800s. The thoughts were produced in writing. The experimenter looked at responses and restricted corrective feedback to situations in which the participants produced short responses during practice (‘OK, makes sense’). When this happened, the experimenter restated the instructions on thinking aloud.

After completing practice, participants were transitioned to the RSAT interface to complete the task on the computer. In the context of the present study, sentences were presented one at a time in isolation and participants were prompted to generate constructed responses after every sentence. When a constructed response was solicited, the sentence that was just read was removed from the screen. This decision was made to force students to draw upon their mental model to produce the constructed response. The sentences were presented at the top of the screen and a ‘Next’ button appeared above a textbox near the bottom. However, while a sentence was present, the textbox was not active. After pressing the next button when there was a sentence present, the sentence disappeared and ‘What are you thinking now?’ appeared above the text box. The textbox then became active, and participants could type their responses. Participants pressed the next button to advance to the next sentence. The phrase ‘Next Paragraph’ appeared when there were transitions to new paragraphs prior to the first sentences in the paragraphs.

5.2.3. Working memory test

A computerized version of the operation span (OSPAN) task was used to measure participants’ working memory (Unsworth, Heitz, Schrock & Engle, 2005). Sets of mathematical operations are presented and participants are asked to indicate if the operation is true or false (e.g., Is 9 / 3 + 1 = 6?; False). Between these mathematical operation trials, a random letter of the alphabet is shown on the screen for participants to remember for later recall. A practice trial was first administered to accustom subjects to the task before they moved on to the experimental trials. Working memory scores were computed by how many correct letters participants could recall in the same order they were originally presented in. Possible scores ranged from 0 to 75.

5.2.4. Reading skill assessment

Reading skill was measured using the Gates-MacGinitie Reading Test (Level 10/12, Form T; MacGinitie et al., 2000). This standardized test presents participants with 48 multiple-choice questions about expository passages. Each reading passage was associated with 2-6 comprehension questions that assess both shallow and deep comprehension by requiring them to make inferences. All participants were given practice questions beforehand and then had 20 minutes to complete the test. Raw scores were collected with 48 being the highest possible score.

5.3. Procedure

The study took place in two sessions. In session 1, participants completed a series of individual difference assessments that were administered in paper and pencil formats (the working memory assessment was distributed in session 2 because it did not fit the paper and pencil format of session 1). Though a range of additional measures were collected in the larger study, the current study focuses exclusively on reading skill and working memory (i.e., Gates-MacGinitie Reading Test and OSPAN). Session 2 involved activities that were administered on the computer, specifically OSPAN and RSAT. Participants first completed the OSPAN followed by the constructed response task in RSAT, wherein the order of presented texts were randomized.

5.4. Linguistic analyses

For the purpose of calculating the linguistic properties of students’ constructed responses, the individual think-aloud responses were aggregated across participants and saved as text files (Allen et al., 2015, 2016). Specifically, the constructed responses produced at the ends of each sentence were aggregated into a single file for each genre of text. Paragraph breaks were added to the aggregated file to preserve the structure and mimic the organization of the source texts. Thus, the aggregated responses resembled the paragraph structure of the source texts. Each participant had two aggregated constructed response files - one for each of the texts they read.

The aggregated constructed response files were analyzed using the ‘Tool for the Automatic Analysis of Text Cohesion’ (TAACO; Crossley, Paquette, Dascalu, McNamara & Baker, 2016), an automated natural language processing tool that processes multiple text files to report various features related to cohesion. We analyzed the cohesion of the constructed responses in terms of the word lemmas and their synonyms at both the sentence and paragraph levels (see Table 1 for index descriptions). Sentence-level cohesion (i.e., adjacent sentence overlap, adjacent 2-sentence overlap) is intended to be indicative of local connections that readers make whereas paragraph-level cohesion (i.e., adjacent paragraph overlap, adjacent 2-paragraph overlap) is indicative of readers’ generation of more distal connections. Whereas adjacent sentence overlap refers to the overlap of lemmas types across consecutive sentences, adjacent paragraph overlap refers to the cohesive overlap of linguistic markers over consecutive paragraphs. Cohesion was assessed using both the words (i.e., lemmas) and their synonyms to provide estimates of both explicit repetitions from the text as well as their semantic associates.

6. RESULTS

All aggregated constructed responses with fewer than 100 words (i.e., 8 students’ responses) were removed from the following analyses because estimates of cohesion are not reliable with responses including fewer than 100 words (Crossley, 2018; Crossley & Kostyuk, 2017; Crossley et al., 2016). The remaining constructed responses produced by participants ranged in length from 102 to 793 words (M = 279.82; SD = 128.59). Table 2 provides the means, standard deviations, and correlations between the linguistic indices.

Participants scored 52.79% (M = 39.49; SD = 16.47) and 58.81% (M = 28.01; SD = 8.34) on the working memory and reading skill assessments, respectively. Performance on these two measures was not significantly correlated (r = 0.10, p = 0.27).

6.1. Relations between individual differences and constructed response cohesion

Our first research question examined the magnitude of the relations between individual differences (i.e., working memory, reading skill) and the cohesion of participants’ constructed responses generated during reading. Table 3 provides the correlations between the individual difference measures and cohesion indices aggregated across genre. The overall correlations indicated that the cohesion observed in readers’ constructed responses was more strongly related to their reading skill than their scores on the working memory task. Indeed, six of the eight cohesion variables were correlated with reading skill whereas none of the cohesion variables were significantly related to working memory. This provides preliminary support that we can predict individual differences amongst readers based on the cohesion of their constructed responses generated during reading.
6.1.1. Machine learning models

To determine how predictive the cohesion indices were of the individual differences, we extended the correlation analyses by developing machine learning models to predict scores on the individual difference measures from the constructed response cohesion variables (see Table 1 for the list of variables used). We used four different models (Linear Regression, Random Forest, Support Vector Machine Polynomial, Bayesian Regularized Neural Networks; see Table 4 for model details) because linguistic features often exhibit nonlinear and complex relations, which are better able to be captured by different models (Kuhn, 2019). The four models were selected because they have been shown to successfully model individual differences from linguistic features in texts (Öncel, Flynn, Sonia, Barker, Lindsay, McClure, McNamara & Allen, 2021).

Linear Regression models predict continuous variables using slope-intercepts (Rong & Bao-wen, 2018). Random Forest models are used to avoid the overfitting problem commonly associated with decision trees by constructing multiple decision trees and using majority voting (Breiman, 2001). Support Vector Machine (SVM) models work by creating separate planes to break data up by their features. However, the current study uses the polynomial kernel, a more generalized representation of the typical linear SVM model (Tong & Koller, 2001). Finally, the Bayesian Regularized Neural Networks (BRNN) functions by assigning weights and biases to a probability distribution (Karklin & Lewicki, 2005). Table 4 provides additional information about the models presented in this study and classifies them by type and tuning parameter (Kuhn, 2019). Aside from linear regression, all models analyze data nonlinearly to account for the nonlinearity of language data. Predictions were then evaluated using R2 and the root-mean-square error (RMSE). To avoid overfitting and maximize the chance of generalizability, all models in the current study utilized a 10-fold cross-validation procedure and were repeated three times.
As shown in Tables 5 and 6, the cohesion indices were able to account for approximately 16-18% of the variance in the working memory and reading skill scores, respectively. In particular, the BRNN model (R2 = 0.18, RMSE = 16.81) performed best for the working memory scores and the Random Forest model (R2 = 0.16, RMSE = 8.04) performed best for reading skill. This indicates that individuals who performed better on the working memory and reading skill tests were engaging in different types of coherence-building processes compared to those with lower scores. Critically, the most important variable in each of the best-performing models was not significantly correlated with the dependent variable. This suggests the presence of nonlinear relations in the data that may have otherwise been missed by relying solely on linear models, such as correlations and regressions.

6.2. Exploration of genre effects

We next examined the correlations between individual differences and cohesion as a function of genre (i.e., history, science). As shown in Table 7, the stability of these correlations varied across genre. We found significant, weak, negative relations between cohesion and working memory (WM) for history texts, but not for science texts. Conversely, significant, but weak positive correlations were observed between cohesion and reading skill (RS; see Table 7) for both the history and science texts, albeit with stronger relations within the history genre. These results suggest that history and science texts may have subtle differential relations to coherence-building processes across skill levels (i.e., individual differences).

To complement the correlational analyses, linear mixed-effects models were used to examine interactions between individual differences and genre in the cohesion of participants’ constructed responses. Participants were treated as random effects because they each had an observation for both a history and science text. Individual difference measures and genre were treated as fixed effects to predict cohesion indices. We selected the cohesion variables with the highest correlation from each level (i.e., sentence-level, paragraph-level, synonym cohesion) and individual difference measure (i.e., working memory, reading skill; see Table 9). For all three models (at each level of cohesion), there was a significant interaction between working memory and genre on constructed response cohesion (p < .01), indicating that relations between working memory and cohesion were moderated by genre. Conversely, we found no significant interactions between reading skill and genre. These results suggest that reading skill was consistently related to constructed response cohesion, regardless of the genre of the text. Overall, these results indicate that both individual differences and genre impact the constructed response cohesion at the sentence-level, paragraph-level, and synonym-levels.

To provide further insights into why the individual differences exhibited such different relations to cohesion in the history domain, we conducted an exploratory, qualitative analysis of the constructed responses with the cohesion variable that correlated the highest. The first five constructed profiles from samples of both low and high scorers on individual difference assessments (working memory, reading skill) appear in Table 8.

As shown in Table 8, the student with lower working memory scores seemed to provide more of a broad paraphrase of the content, rather than engage in more self-reflective thought. The individual with high working memory scores, conversely, wrote fewer words but asked more targeted, specific questions about the text. Question asking has been shown to be a particularly beneficial reading strategy that can aid in coherence-building and comprehension (Palincsar & Brown, 1984; Rosenshine, Meister & Chapman, 1996; Graesser, McNamara & VanLehn, 2005). Thus, this person may be more efficiently leveraging their working memory capacity with more useful responses to the text, as further evidenced by our quantitative results.

Regarding reading skill, Table 8 reveals that the less skilled readers made very few connections across the text and did not provide any indication of strategic processing. Conversely, the high skilled reader engaged in more metacognitive monitoring while reading, as the reader described thoughts regarding how the text related to personal knowledge and experiences. Overall, this qualitative examination of the constructed responses illustrates how individual differences in working memory and reading skill may manifest differently in the properties of constructed responses.

7. DISCUSSION

A central assumption of the present study is that constructed responses reveal important insights into individual difference factors associated with comprehension (Allen et al., 2015, 2016). The present study builds on the robust body of work that has examined relations between individual difference measures and constructed responses (Whitney et al., 1991; Bohn-Gettler & Kendeou, 2014; Magliano et al., 2020) by leveraging novel NLP and machine learning methodologies. We leveraged an NLP approach developed by Allen et al. (2015, 2016) to analyze the cohesion of readers’ constructed responses across two different text genres (i.e., history and science). Cohesion was calculated for the constructed responses at three levels: sentence, paragraph, and synonym cohesion. Our primary objective was to examine if readers’ individual differences in working memory and reading skill could be reliably predicted from the cohesion of their constructed responses while reading and the extent that these relations varied across genres.

7.1. Predicting individual differences

The results of our correlation analyses indicated that all but two of the cohesion indices were correlated with reading skill; however, none of the indices were correlated with working memory. This is consistent with theoretical frameworks that emphasize the importance of the proficiencies in linguistic processes over general resources like working memory (Perfetti & Stafura, 2014). Although working memory capacity has implications on the waxing and waning of activated knowledge during reading (Just & Carpenter, 1991), accurately representing content serves as the primary retrieval cue for that knowledge (Myers & O’Brien, 1998). Thus, proficiency in processes that support the construction of strong mental representations of the explicitly conveyed content have direct effects on coherence-building (Gernsbacher, 1997; Kintsch, 1998).

Despite these differences in the correlation analyses, the subsequent machine learning analyses indicated that both reading skill and working memory could be predicted by the constructed response cohesion variables. This suggests that variance associated with both reading skill and working memory was related to the ways in which students generated connections during reading. Importantly, the most important variable in the models was ‘adjacent paragraph verb synonym’, which was not significant in the correlational analyses. This suggests a more complex, nonlinear relationship between the cohesion indices and individual differences, which should be explored in future studies.

Finally, the qualitative analysis of the constructed responses yielded important insights into how individuals who scored lower and higher on the working memory and reading skill assessments approached coherence-building. With respect to working memory capacity, lower span readers tended to produce responses that reflected the local context, whereas higher span readers produced relatively shorter responses but reflected that they were sensitive to the global context. These results are similar to those reported by Whitney et al. (1991) in the context of thinking aloud while reading narratives. With respect to reading skill, less skilled readers did not demonstrate strategies that are typically reflective of coherence-building, such as bridging across explicitly conveyed ideas and elaborating based on knowledge external to the texts (McNamara, 2004). More skilled readers demonstrated evidence of metacognitive strategies that tend to be associated with successful comprehension (Pressley & Afflerbach, 1995). These strategies are important for determining when specific coherence-building strategies are important and need to be deployed (McNamara & Magliano, 2009). The combination of computational analysis and more qualitative discourse analysis used in this study was critical in understanding the complex nature of the results.

7.2. Genre effects

The genre-level correlation analyses again revealed that constructed response cohesion was significantly correlated with reading skill for both history and science texts, indicating that the skilled readers generated more connections in their constructed responses regardless of the genre. However, the results were less clear for working memory - participants’ scores on the working memory test were negatively related to constructed response cohesion in the history texts and unrelated to science texts. The mixed-effects models corroborated this finding as genre and working memory interacted for every level of cohesion (sentence, paragraph, synonym). These results are in line with prior work in text comprehension that has found differential processing amongst text genres (McNamara et al., 2012; Clinton et al., 2020; Mar et al., 2021). However, none of the interactions between reading skill and genre were significant.

Given the robust feature- and function-based differences found across text genres (Parodi, 2010, 2014, 2015), the history and science texts here likely had varying task demands from the readers. Despite these differences, however, reading skill seemed to have consistent and stable relations to the coherence-building processes measured by the cohesion analyses. Given that reading skill is a malleable skill (unlike working memory), this suggests that difficulties associated with coherence-building may be more easily remedied through strategy instruction (McNamara, 2004). Therefore, researchers should focus on reading skill interventions to improve reading comprehension, rather than attempting to focus on capacity limitations due to working memory capacity. Based on our findings, this approach may be more likely to be fruitful, as it would be more likely to transfer to new and varied discourse contexts. However, future research might consider systematically examining these relations between working memory, genre, and coherence-building processes to develop a more thorough understanding of how such individual differences impact the coherence-building process.

7.3. Implications for theories of reading and comprehension

Theories of comprehension universally specify that coherence-building is a foundation of comprehension (McNamara & Magliano, 2009), but most are agnostic regarding the extent that individual difference factors support coherence-building. In contrast, theories of reading typically specify these relationships (e.g., Cromley & Azevedo, 2007), but underspecify the nature of and importance of coherence-building (Magliano et al., 2020). The results of the present study indicate that a comprehensive model that describes how individual differences support coherence-building is warranted but, to our knowledge, there is no formal model that describes how reading and coherence-building operate. The Reading Systems Frameworks (Perfetti & Stafura, 2014) is a step in this direction but was proposed to provide a heuristic for formulating research questions rather than a formal model. Gernbacher’s structure building model provides an exception as it was proposed to describe the basic processes of coherence-building and how some individual difference factors (e.g., knowledge suppression) support comprehension (Gernsbacher, 1997; Gernsbacher et al., 1990). The present study underscores the need for further development of a comprehensive model of reading and comprehension (e.g., McNamara & Magliano, 2009).

7.4. Implications for the computational assessment of constructed responses

There are two basic approaches to the computational analysis of constructed responses to assess coherence-building. One approach involves analyzing the semantic overlap between the constructed responses and the texts (Magliano & Millis, 2003; Magliano et al., 2011; Magliano & Graesser, 2012). This approach rests on the assumption that level of overlap with different aspects of the text is indicative of strategies associated with the prior discourse context. For example, constructed responses with greater overlap with the current sentence were more likely to reflect responses that paraphrased that sentence. In contrast, constructed responses with greater overlap with prior discourse sentences were more likely to reflect the use of bridging strategies to specify how the current sentence is related to the prior discourse context. There is evidence that this approach is related to both language-specific (Feller, Magliano, Sabatini, O´Reilly & Kopatich, 2020; Kopatich et al., 2019; Magliano & Millis, 2003; Magliano et al., 2011, 2020) and domain-general (Kopatich et al., 2019) individual difference factors.

The present study reflects a different approach to assess coherence-building. Namely, we were able to leverage automated, NLP techniques to detect cohesion in students’ responses. Rather than comparing the constructed responses to the text, these analyses examine the relations across students’ responses. This provided a means to model the connections that students were making while reading without having to rely on human raters’ judgments of the accuracy of these connections. Cohesion analyses, thus, allow us to examine connections made at the level of the individual student.

Rather than competition across these approaches, we see the combination of these methods as a critical future direction for more meaningfully evaluating how readers engage in coherence-building and for understanding how these processes vary across readers and across contexts. Further, reading comprehension skills are better modeled when taking both the quality and features of readers’ online constructed responses into account (Allen et al., 2015). The current study only examined cohesive features of readers’ responses, but future extensions should focus on further analyzing the qualitative quality of the constructed responses.

One of the primary limitations of the current study is its sample size. The analyses discussed above may be further strengthened if future studies replicate these findings with a larger and more diverse sample. A larger sample size would also afford examining a broader array of linguistic features such as syntax, semantics, or lexicality, which may provide additional power to predict individual differences. A second limitation is the nature of the general reading comprehension measure. There is a current debate as to whether the Gates-MacGinitie Reading Test accurately assesses deep comprehension skills (Cutting & Scarborough, 2006; van den Broek & Espin, 2012). For this reason, additional measures of deep reading comprehension should be used to assess reading skill in future studies.

CONCLUSIONS

Despite these limitations, the current study has important implications for the realm of computational analysis and educational technology. Our results suggest that constructed response cohesion may aid researchers in the implementation of stealth assessments (e.g., Shute & Ventura, 2013). Stealth assessments refer to evaluations of student learning that occur during practice or game-play rather than through summative evaluations. Stealth assessments afford real-time in situ evaluation of students’ reading processes. Therefore, future studies should examine how these NLP analyses can be deployed in real-time to provide students with feedback on their text comprehension strategies. Implementing these assessments may allow educational technologies to better model students’ individual differences, which can lead to the development of more adaptive and personalized feedback that promotes the use of the right coherence-building strategies at the right time.

