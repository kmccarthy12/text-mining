Coherence-building in multiple document comprehension

Abstract 
The current study examined the extent to which the cohesion detected in readers’ constructed responses to multiple documents was predictive of persuasive, source-based essay quality. Participants (N=95) completed multiple-documents reading tasks wherein they were prompted to think-aloud, selfexplain, or evaluate the sources while reading a set of four texts. They were then asked to write a source-based essay based on their reading. Natural Language Processing techniques were used to automatically analyze the cohesion of the constructed responses at both within- and acrossdocuments levels. Results indicated that within-document cohesion was negatively related to essay quality, whereas across-documents cohesion was positively related to essay quality. Further, these relations differed by instructional condition such that strategic instructions to either self-explain or evaluate sources seemed to promote across-text integration, compared to thinking aloud. Overall, this study indicates that the cohesion of constructed responses to text can provide insights into the coherence of the mental representations readers construct while reading multiple documents. 
Keywords: comprehension; cohesion; writing; natural language processing 
Introduction 
The processing and comprehension of texts is a complex process that is ubiquitous in our contemporary, informationdriven society (Rouet et al., 2017). Despite its prevalence, reading is difficult and relies heavily on multiple levels of knowledge (e.g., vocabulary, domain) and strategies for integrating this knowledge with text content (McNamara & Magliano, 2009). The majority of text comprehension models agree that the outcome of this process is a mental representation of the text content (e.g., Gernsbacher, 1990; Kintsch, 1998). This representation is said to be coherent to the extent that a reader establishes connections amongst the text information, as well as to relevant prior knowledge. Thus, successful comprehension relies on creating, maintaining, and updating these connections while reading. 
Importantly, much of the prior work in this area has focused on how individuals process, comprehend, and remember single texts, despite the fact that individuals rarely rely on only one text when they are attempting to learn new information (Magliano et al., 2018). In response to this gap, there has recently been a growing interest in examining how individuals comprehend multiple documents, particularly when they may include of mixture of reliable and unreliable sources or contain conflicting or inaccurate information. In this multiple document (MD) context, individuals must not only have the knowledge and strategies necessary to comprehend each individual document, but also to evaluate the quality of the sources, integrate the information presented across the documents, and use this information to ideally provide a well-reasoned argument (Braasch et al., 2018).  
Despite these differences, it has been commonly assumed that the basic processes in single text comprehension contexts go relatively unchanged in MD contexts. Research has therefore predominantly focused on examining the influence of source reliability rather than examining how basic processes, such as integration, unfold in this MD reading context. The purpose of the current study was to conduct a fine-grained analysis of the processes underlying MD comprehension and to examine how those processes might vary across instructional conditions. Below, we provide a brief overview of prior work on MD comprehension followed by a discussion of how constructed responses (e.g., thinkaloud protocols) have been used to examine individuals’ online processes during reading. We then provide a 
description of the current study, our results, and a discussion of limitations and directions for future work. 
Multiple Document Comprehension  
Theories of MD processing emphasize the importance of sensitivity to the sources of documents (i.e., sourcing) as an important process for comprehending texts (Rouet et al., 2017; Braash, & Braten, 2017) – this process involves the evaluation of the authors, their credentials, the publisher, etc.  Source is seen as important for MD processing because there can be dramatic differences in the reliability of the sources that may be encountered in an MD task. This importance is evident in an era where anyone can publish information on the internet (Magliano et al., 2018). However, effective sourcing requires a strategic evaluation of the creditability of the information being provided in the texts (Rouet et al., 2017). As such, interventions in MD contexts have commonly focused on increasing individuals’ attention to source information through either instructions to engage in sourcing or through more extensive source evaluation training (Braasch, et al., 2018). 
 
Source-based Essays MD comprehension is commonly evaluated with source-based essays, both due to their theoretical alignment with the comprehension process and their practical alignment with classroom activities. These source-based essay tasks often ask participants to read a set of documents to then compose an argumentative essay. Less skilled students tend to construct source-based essays that are either over-compartmentalized (e.g., abstract stacking) or too generalized (i.e., a “mush model”). By contrast, high quality source-based essays are well-organized in a way that reflects the integration of ideas spread across the document set. 
Constructed Responses During Reading 
Prompting readers to generate constructed responses as they read is a common method of both engendering different comprehension processes and a way of studying the cognitive processes that occur during reading. In the present study, we used three constructed response types that are relevant for multiple document comprehension: think-aloud, selfexplanation, and source evaluation (described above).  
Think-alouds are perhaps the most well-established procedure for collecting individuals’ thoughts during reading (Pressley & Afflerbach, 1995). When thinking aloud, readers are intermittently interrupted and asked to report their thoughts as they come to their mind; as such, these instructions are relatively neutral in that they do not bias readers to adopt a particular strategy (Ericsson & Simon, 1994). Think-aloud studies have aided in the identification of processes involved in comprehension across a variety of contexts (Magliano et al., in press). Particularly relevant to the current study is work suggesting that skilled readers tend to not only generate more inferences, but also tend to make more global connections, rather than only local connections (e.g., at the level of adjacent sentences; Millis et al., 2006). 
MD tasks require readers to represent important relationships conveyed both within and across texts (Rouet & Britt, 2011). Readers must develop goals and strategies that promote integration across texts and, in particular, when the task requires such integration (e.g., writing an essay based on multiple documents (Rouet et al., 2011).  Self-explanation is one strategy that may help readers make these connections. Self-explanation involves monitoring your own understanding and explaining the text to yourself as you read. Engaging in self-explanation can lead to increased inference generation and connections to prior knowledge, which supports deeper comprehension (McNamara, 2004). 
Establishing these types of connections is especially critical in MD scenarios in which there are more distal connections between ideas and fewer discourse markers to support inference generation than in single document scenarios (Goldman & Rakestraw, 2000). Indeed, think-aloud protocols collected during MD tasks have demonstrated that skilled readers are more likely to engage in self-explanation strategies than less skilled readers (Anmarkrud et al., 2014; Goldman, et al., 2012). Despite this, there have been few investigations into the extent to which self-explanation may actually increase across-document connections and promote the successful comprehension of multiple documents.  
 
Cohesion in Constructed Responses As previously described, the connections individuals generate during reading are representative of the coherence of their mental representation of the text. Coherent mental representations have been shown to be important for deep comprehension of texts (McNamara & Magliano, 2009). However, coherence cannot be directly measured but instead must be inferred from comprehension assessments or computational models that simulate comprehension processes (e.g., Kintsch, 1998).  
One way to assess coherence indirectly is by measuring cohesion. Cohesion refers to the explicit cues in text that establish connections amongst text content (Gernsbacher, 1990; McNamara et al., 2014). For example, repeated words across the sentences of a text can signify that the sentences are focused on similar concepts. Recent work suggests that the cohesion of individuals’ constructed responses during reading may be indicative of the coherence of their mental representation (Allen et al., 2015; 2016). Allen and colleagues (2016) found that the cohesion of constructed responses was higher when readers were prompted to selfexplain compared to paraphrase, and that the cohesion of individuals’ constructed responses increased over the course of self-explanation training. Thus, research suggests that cohesion may be indicative of coherence-building processes during comprehension; however, this hypothesis has yet to be tested in a MD comprehension context.   
Current Study 
The purpose of the current study was to examine the extent to which the cohesion detected in readers’ constructed responses was predictive of persuasive, source-based essay quality. Here, we adopt a methodological approach that relies on theoretically motivated natural language processing (NLP) techniques wherein we use the language that participants produce as they read to understand how they are establishing connections within and across the texts in a multiple-documents scenario. In particular, we manipulated the instructions that participants were given before reading a 
set of texts. Participants were instructed to think-aloud, selfexplain, or evaluate the source material. We then calculated linguistic indices related to the cohesion of these constructed responses that we hypothesized would be indicative of coherence-building within and across the documents.  
Natural language can exhibit cohesion in a variety of different ways. Here, we focus on one form of cohesion - lexical cohesion (Crossley et al, 2018). Lexical cohesion refers to cohesion that manifests in the form of overlapping words across a text. That is, if a participant’s constructed responses often repeat the same (or semantically similar) words, that participant is demonstrating high lexical cohesion across their responses.  
Importantly, prior studies have shown that withindocument cohesion is predictive of comprehension and reading skill for single text comprehension (Allen et al., 2015; 2016); however, this finding has yet to be generalized to a multiple document context. In the current study, we calculate lexical cohesion not only at the individual document level (within-document cohesion), but also across an entire document set (across-document cohesion). Thus, we examine the extent to which both within- and across-documents lexical cohesion manifests in individuals’ constructed responses and whether this cohesion relates to the quality of essays written after the reading task. We expect that in the context of MD comprehension, more complex connections captured by across-documents cohesion measures will be more important for performance than the role of withindocument cohesion seen in single text scenarios. Finally, we examine whether these relationships between cohesion and essay quality are moderated by instructional condition. 
Thus, we aim to answer two primary research questions. The more focal question was How do the within- and acrossdocument cohesion indices in participants’ constructed responses relate to the overall quality of participants’ postreading source-based essays? We also manipulated reading instructions in order to generate a variety of types of processes that readers engage in during both single and multiple-documents comprehension tasks. These different strategies have been shown to differentially impact comprehension (e.g., Allen et al., 2015; Britt & Aglinskas, 2002). Thus, a second research question was: To what extent do different comprehension strategies (i.e., constructed response instructions) influence the relation between the cohesion in the responses and source-based writing quality? 
Method 
Participants 
Participants (N = 95) included 46 high school students (Mage 
= 16.3, SDage = .99) who participated in the study in the Summer of 2019 and 49 college freshmen students who had graduated high school the previous year (Mage = 18.1, SDage = .89) and participated in the Fall of 2020. All participants were native speakers of English. Data for two participants were removed from the analyses for failure to follow instructions, leaving 93 participants in the final analysis.  
Materials & Measures 
Constructed Response Instructions Participants were assigned to one of three instructional conditions; think-aloud, self-explanation, and source evaluation. The think-aloud condition served primarily as a control condition wherein participants were asked to “report their thoughts” as they read through the texts to try to match for time-on-task. Participants in the self-explain condition were asked to try to explain the text to themselves as they read. Participants in the source evaluation condition were asked to reflect on the source (i.e., author, publication, date/locations, audience) of the text while they read.  
 
Document Sets Each document set contained four texts; one set was focused on the effects of global warming and the other was focused on cell phone use. The presentation of the texts was counterbalanced and randomly assigned. For the global warming set, there were two texts that discussed whether the causes of global warming were natural or manmade and two that discussed the negative and positive consequences of global warming. For the cell phone use set, two of the texts focused on the argument that cell phone use could increase cancer risk and two discussed the argument against radiation from cell phone use causing cancer.  
At pre-determined sentences (6-9 sentences in each document), participants were prompted to generate their constructed response (e.g., think-aloud, self-explanation, source evaluation). 
 
Source-Based Essay After reading the document sets, readers were asked to write an essay that either 1) explained the effects of climate change for life on earth and the extent to which humans are responsible or 2) explained the effects of cell phones on humans and the extent to which cell phone use poses health risks. Participants were asked to elaborate on the information in the text instead of summarizing. They were also asked to use information from the texts to support their ideas, but to put ideas in their own words. 
Study Procedure 
Participants completed the study using the MD module of iSTART (McNamara et al., 2004). They completed two MD tasks on different topics (global warming, dangers of cell phone use). In each task, they read four texts and then wrote an essay. Before reading, participants were given a chance to skim the texts before engaging in the deeper reading process. During the actual reading portion of the experiment, participants were prompted to think-aloud (n = 30), selfexplain (n = 32), or evaluate the sources (n = 31). They were then given 25 minutes to write a source-based essay. In a second session, they completed the same reading and writing task with the alternate text set.  
Analyses  
Automated Cohesion Analyses To prepare participants’ constructed responses for cohesion analysis, we aggregated the responses in two different ways: within-document (all constructed responses for a given text) and across-document (all constructed responses for a given document set). Participants’ constructed responses were analyzed using TAACO (Crossley et al., 2018). For the purposes of the current study, we selected indices that were representative of lexical cohesion at within- and across-document set levels. For each level, we looked at four types of cohesion: content words, verbs, arguments, or all words. 
 
Source-based Essay Quality The essays were evaluated using a scoring rubric that included four analytic scores and one holistic score. Given the scope of the current paper and the relatively small sample size, here we focus only on the holistic scores, which ranged from 1 (very poor) to 6 (excellent). Human ratings for the scores were provided by two teams of two expert raters each. The raters were PhD students in an English composition program, who had over three years of experience teaching writing at the university level and rating experience with standardized rubrics. The raters were first trained on the rubric using essays that were not part of the corpus used in this study. When raters reached an acceptable level of reliability (Kappa > .70), they scored the source-based essays in the current study such that two raters scored each essay. After initial scoring, Kappa scores ranged from .48 to .65. Raters then adjudicated their scores together. If any differences in scores were greater than 1, raters discussed the scores and made adjustments as needed. After adjudication, all Kappa scores were greater than .6.  
Results 
For all participants, we collapsed the cohesion and essay scores across document sets. Thus, each participant had an average set of cohesion indices as well as an average essay score. The average holistic essay scores did not differ for participants who were randomly assigned to the think aloud (M = 2.82; SD = 0.85), self-explanation (M = 2.91; SD = 0.90), or source evaluation (M = 2.70; SD = 0.95) conditions, suggesting that the experimental manipulation did not lead to differences in overall essay quality [F(2, 90) = 0.41, p = 0.67]. 
Cohesion and Essay Quality 
Our first research question considered whether the within- and across-document cohesion of participants’ constructed responses were related to the overall quality (i.e., holistic score) of their essays. Pearson correlations between average within-document cohesion and holistic essay scores revealed reliable negative correlations, indicating that connections made at the individual document level were negatively related to overall essay scores (see Table 1 for all correlations). Conversely, across-document cohesion indices were positively correlated with essay score, suggesting that connections made across documents in the document set were indicative of higher quality source-based essays.   
We conducted a multiple regression analysis to determine how much variance could be explained in participants’ essay scores from the within- and across-documents cohesion indices. For this model, we selected only the two indices with the highest correlation from each of the within and across cohesion groups. Thus, our independent variables were within- and across-documents content word and argument cohesion, respectively. This analysis yielded a significant model that accounted for approximately 19% of the variance in the holistic essay scores, R2 = .19, F (2, 90) = 10.34, p < .001. Importantly, there were main effects of both within (p < .001) and across documents cohesion (p < .001), indicating that connections made during reading at local text levels as well as across the entire document set were related to the overall quality of the essays produced after reading.  
Overall, the results of this first set of analyses suggest that the cohesion of participants’ constructed responses in a multiple document context is predictive of holistic score on a 
source-based essay. Importantly, within- and acrossdocuments cohesion exhibited different patterns of relations with essay quality. Connections made across the document set were positively related to essay quality, whereas withindocument cohesion was negatively related to quality. This suggests that while cohesion is a relevant predictor, it not the case that more cohesive responses are inherently better for source-based writing. 
Effects of Instructional Condition 
As mentioned previously, the instructional condition had no significant effect on overall essay quality. However, it is likely that these instructions influenced the types of comprehension processes that participants engaged in as they read (e.g., Allen et al., 2015). Thus, our second research question regarded whether the relationship between the within- and across-documents cohesion indices and essay scores was moderated by instructional condition. In other words, we aimed to determine whether instructions to simply think-aloud, self-explain the texts, or evaluate the source material would alter the relationship between cohesion and essay quality. To this end, we first computed group-level Pearson correlations for both within- and across-documents cohesion and holistic essay quality (see Table 2). Here, we used the same cohesion indices that were used in the prior analysis; thus, the variables for within- and across-documents cohesion were calculated for content word and argument, respectively. 
Results indicated that there were differential relations between cohesion indices and essay quality as a function of condition. For within-document cohesion, the think-aloud condition exhibited a reliable (negative) relationship with essay quality; however, the relations in the other two conditions did not achieve significance. Conversely, for across-document cohesion, the self-explanation and source evaluation conditions exhibited positive correlations with essay quality, whereas the think-aloud condition did not.  
In a follow up analysis, we examined whether there was an interaction between the cohesion indices and condition. This interaction did not reach significance for either within- (p = 0.45) or across-documents cohesion (p = 0.40). Thus, while the correlational analyses reveal some interesting patterns, there was not a reliable moderation effect of condition.  
Exploratory Analysis of Condition Effects 
As an exploratory analysis, we examined simple slopes in order to determine whether there were differences in the correlations between the cohesion indices and essay scores across the conditions. Despite the lack of significant interaction, there was a significant difference in the simple slope for the think-aloud condition for within-document cohesion (p = .05; see Figure 1). For across-documents cohesion, the simple slopes for self-explanation and source conditions were significant (p = .04 and p < .01, respectively; see Figure 2). These results indicate that for individuals in the think-aloud condition, the negative influence of local connections was more important for essay quality, whereas for participants in the strategic instructional conditions (i.e., self-explanation and source evaluation), integration across the document set during reading was more predictive of essay quality. It is important to note that this analysis was purely exploratory and future research is needed to determine how these experimental conditions may differentially impact the relations between constructed response cohesion and sourcebased essay quality. 
Discussion 
The current study investigated the hypothesis that cohesion could serve as a signature of the coherence of a reader’s mental representation; thus, we aimed to examine whether the cohesion of participants’ constructed responses was related to the overall quality of their source-based essays. We anticipated that within- and across-documents cohesion would behave differently, given that integration of multiple documents may rely on more strategic processing than within a single document. Thus, we expected across-documents cohesion to relate positively to source-based essays, as success on this task relied heavily on individuals’ integration of information across the document set. Additionally, we examined whether these relations were moderated by instructional condition.  
The results of our analysis provided evidence in support of our first prediction. Specifically, cohesion indices of participants’ constructed responses were related to holistic essay quality. Consistent with the assumption that MD tasks require integration across a document set (Rouet & Britt, 2011), across-documents cohesion was positively related to essay quality. Conversely, within-document cohesion was negative correlated with essay performance. This may seem anomalous because evidence of within-text integration in think aloud protocols is typically positively correlated with comprehension outcomes (e.g., Magliano et al., in press). One interpretation of this finding is that participants who had higher levels of within-text cohesion were adopting a strategy for the MD task that involved comprehending the texts in isolation, rather than creating an integrated representation. 
Our second research question was exploratory and examined whether instructional condition moderated the relationship between cohesion and essay quality. The relationship between type of cohesion and performance varied across conditions. The negative relationship between within-texts cohesion. and essay performance was present in the think aloud condition, suggesting that thinking aloud may have encouraged readers to focus on comprehending the texts in isolation. Conversely, across-documents cohesion was positively correlated with essay scores in the self-explanation and source evaluation conditions. These instructions may have more effectively oriented participants to engage in the within-text integration necessary to write effective essays. 
These findings are important for multiple reasons. First, they provide further evidence for a theoretical link between cohesion and coherence and suggest that cohesion cues in constructed responses can potentially provide a proxy for coherence-building processes during reading. Second, they extend prior work in this area to a MD reading context; in particular, this study attempts to more systematically examine how integration within and across documents relate to comprehension. Importantly, we found that withindocument and across-documents cohesion were differentially related to post-reading essay scores, suggesting that integration within a single document is orthogonal to acrossdocuments integration processes.   
Importantly, this study is only an initial exploration of our research questions and thus has a number of limitations. Additional studies will be necessary to more thoroughly examine relations between cohesion and post-reading outcomes in MD contexts. First, we only focused on lexical cohesion of participants’ constructed responses. Research has identified a number of ways in which individuals can establish cohesion in text (Crossley et al., 2018). More nuanced comparisons of different forms of cohesion may shed light on the relations between cohesion and coherence, particularly in MD contexts. Second, the current study was not sufficiently powered to conduct thorough examinations of our experimental groups. Thus, future studies are planned to replicate these findings and further examine whether and how instructions moderate relations between cohesion and essay quality. Finally, further research is needed to examine the generalizability of our results across different types of document sets and different types of comprehension goals.  
Overall, the current study takes an important step towards understanding the role of integration in MD comprehension tasks; in particular, it provides preliminary evidence that the cohesion of participants’ constructed responses can provide insights into the coherence of mental representations. Results of this and future work can strengthen our theoretical understanding of MD comprehension processes, as well as how these relate to source-based writing performance.  
