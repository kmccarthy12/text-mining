Effects of adapting text difficulty in an intelligent tutoring system. 

ABSTRACT: Adapting tasks to the individual has been shown to improve learning, and improve learners’ experiences in the learning process.  This study investigated how adaptive task selection affected learners’ experiences in iSTART, an intelligent tutoring system for improving reading comprehension. Participants (n = 59) engaged with iSTART for 7 hours across three sessions. Participants read and self-explained texts that were presented in random order or adaptatively based on participants’ performance. Adaptive task selection did not increase engagement, but did enhance participants’ judgments of learning. 
Keywords: Intelligent Tutoring System, Scaffolding, Motivation.
1	INTRODUCTION
Interactive Strategy Training for Active Reading and Thinking (iSTART; McNamara et al., 2007) is an intelligent tutoring system (ITS) that provides reading comprehension strategy instruction through videos lessons, and game-based self-explanation practice. Recently, we have implemented adaptive text selection to increase individualization of instruction. An algorithm selects the difficulty of texts that the learner reads and self-explains based on their average self-explanation (SE) score (0-3). When average SE score is above a threshold (2.0), the algorithm selects a subsequent text that is more difficult. When the SE score is below the threshold, the algorithm selects an easier text. This adaptive task selection has effectively improved student learning (McCarthy et al., 2018). 
Adaptivity may also benefit student experiences with the system. Scaffolding tasks to a learner’s zone of proximal development (ZPD) has been shown to improve learners’ motivation and engagement (Murry & Arroyo, 2002). Thus, this study used students’ survey responses to investigate how adaptive task selection affected learners’ experience (e.g., engagement, motivation, metacomprehension) during training. It was hypothesized adaptive text selection better targets students’ ZPD, which may in turn enhance learners’ experiences with iSTART. 
2	METHOD
Participants (n = 59) engaged in 3 sessions (~7 hours) of iSTART training in which they are presented science texts and asked to write self-explanations during reading. In the random condition, participants received texts in random order. In the adaptive condition, an algorithm selected texts based on the participants’ average self-explanation scores. At the end of each session, participants’ answered 5-point Likert scale items about that day’s training (Table 1). To account for differences in trait-level motivation, participants also completed the Learning Orientation (LO) and Performance Orientation (PO) scales (Jha & Bhattacharyya, 2013). 
3	RESULTS
T-tests indicated no differences across conditions in LO, t(57) = .21, p = .83, or PO, t(57) = .24, p = .81. Nonetheless, LO was included as a covariate in subsequent analyses.
A series of 2(condition: random, adaptive) x 3(session: 1, 2, 3) ANCOVAs revealed no changes across sessions (all Fs < 1.00). Adaptive task selection had no significant effect on learners’ overall experience or enjoyment of iSTART, nor did adaptivity increase negative experiences (boredom, frustration). However, participants in the adaptive text selection condition more strongly agreed that they learned the material presented in the texts that they had read (Table 1).
4	DISCUSSION
Consistent with the theory of learners’ ZPD, adapting the difficulty of a task to the learner increased their sense of learning. However, adaptivity had no significant effect on learners’ self-reported enjoyment or engagement. Future work will explore log data to examine how task adaptivity impacted more moment-to-moment experiences in iSTART and how the effects of adaptivity may depend on learners’ individual differences in skills.
