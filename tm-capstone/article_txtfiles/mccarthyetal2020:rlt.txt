The Russian Language Test: Towards assessing comprehension in Russian

Abstract

Reading comprehension relies on a variety of complex skills that are not effectively assessed by existing Russian language tests. At the same time, Russian textbooks are criticized both for their low text quality and high text complexity. This study addresses issues of Russian language proficiency and comprehension assessment with the development of the Russian Language Test (RLT). The RLT was constructed to measure proficiency relevant to textbook comprehension, such as grammar and vocabulary knowledge, establishing propositional meaning and inferencing. Results from this initial study including 81 fifth-grade and 94 ninth-grade students confirm that students struggle with grammatical inferences and identifying the main idea in a text. Additionally, three standardized Russian exams, VPR, OGE, EGE are analyzed, affording an overview of the testing system for the Russian language from the elementary through high school education levels. This study demonstrates promise for the use of the RLT as a language proficiency assessment and provides a broad context for understanding the current state of Russian language tests for native speakers of the Russian language. 

Key words: Russian Language Test, language assessment, comprehension skills, grammar, vocabulary knowledge, gender, age, general knowledge 

Introduction
Russian elementary schoolers outperform students from all other nations on the PIRLS, but underperform on the PISA [Ivanova, 2009]. One explanation for these differing levels of performance is that the majority of questions on the PIRLS are retrieval-based, whereas the PISA has a larger number of items directed at interpretation, integration, and evaluation [Zuckerman et al., 2013].  Indeed, analyses of Russian textbooks and instruction have indicated that students tend to be encouraged to engage in rote memorization rather than meaningful comprehension and the language in these  Russian books is often either overly simplistic [Meyer 2016; Pinskaya, 2009] or too complicated for the target audience [Kuchma, 2015; Ocenka didakticheskoj …, 2016; Solnyshkina et al., 2018, pp. 276-285]. Text that is not matched to readers’ abilities can lead to issues such as lack of motivation, boredom, or frustration [Ponimanie shkol'nikami …, 1985], which in turn can hamper students’ acquisition of academic reading skills. 
Russian academic texts have been described by experts as obscure, with excessive nominalization, ambiguous impersonal structures, as well as complicated, and even erroneous syntax [Integraciya obrazovaniya, 2018; Khoutyz, 2013]. Thus, a major focus of educators in Russia is to assist students in developing sufficient reading comprehension skills to help them learn from more complex academic text. One limitation is that there is no short standardized placement test for native speakers that assesses both lower-level and higher-order proficiencies in Russian. This project outlines the first step in an iterative development of a Russian Language Test.
Study
The current study is a part of an on-going Project initiated by Kazan Federal University in 2017 and aimed at evaluating the quality and text complexity of textbooks used in the Russian Federation [Solovyev et al., 2018, Solovyev et al., 2019 (1), (2), Petrova et al, 2019]. The Project is organized in three stages: (1) testing participants’ reading comprehension proficiency in Russian and the language of the textbooks they use; (2) measuring participants’ individual differences in general knowledge and five cognitive domains that impact performance using the Wechsler’s Intelligence Scale for Children (WISC; 5th graders, aged 11-12) and the Wechsler Adult Intelligence Scale (WAIS; 9th graders, aged 15-16); and (3) evaluating effect of different linguistic features of a printed text on participants’ comprehension.   
In this article we present the first two stages of the Project and proceed from the viewpoint that a student’s limited proficiency in the language of the exam or test may become a barrier to assessing abilities within particular disciplines. That is, such content tests may be a measure of reading comprehension rather than an assessment of the students’ knowledge of ability in the given domain [see Bowles 2008]. In this project, developed a Russian language test which could be used nationwide to isolate students’ reading comprehension skill. This test score can then be used to examine the degree to which participants’ scores in a subject comprehension test may be influenced by reading comprehension issues rather than content issues.
We first discuss the theoretical motivation of assessing multiple levels of proficiency. We then outline strengths and weaknesses of the extant assessments in the context of these theories. We then discuss the development of the Russian Language Test. Finally, we provide results from an initial implementation of the test with fifth and ninth grade students.
Theoretical Background
The test evaluation procedure is based on a generally accepted view that during reading “we process at different levels simultaneously and draw on both bottom-up and top-down processes in establishing meaning” [Research Notes, 2008, p. 3]. We were guided by Weir’s (2003) model of reading to examine seven aspects of reading comprehension. These different aspects reflect both lower-level processes (e.g., decoding) and higher-order processes (e.g., comprehension). The seven terms are: 1) word recognition defined as the ability to “match the form of a word in a written text with a mental representation of the orthographic forms of the language” [Weir, 2003, p. 6]; 2) lexical access is the ‘retrieval of a lexical entry from the lexicon, containing stored information about a word’s form and its meaning.’ The form includes orthographic and phonological mental representations of a lexical item and possibly information on its morphology [Field, 2004, p. 151]; 3) Syntactic parsing involves grouping “words into phrases, and into larger units at the clause and sentence level to understand the message of the text” [Weir, 2003, p. 6]; 4) Establishing propositional (core) meaning at the clause or sentence level is defined as “a literal interpretation of what is on the page. The reader has to add external knowledge to it to turn it into a message that relates to the context in which it occurred [Weir, 2003, p. 6]. 5) Inferencing as “a creative process whereby the brain adds information which is not stated in a text in order to impose coherence [Weir, 2003, p. 6]; 6) Building a mental model “entails an ability to identify main ideas, to relate them to previous ideas, distinguish between major and minor propositions and to impose a hierarchical structure on the information in the text” [Field, 2004, p. 241], it is when “the propositions representing the meaning of a text are linked together, usually by argument overlap, to form a hierarchical text base” [Kintsch and van Dijk, 1978, p. 374]. 7) Creating a text (or discourse) - level structure implies not only recognizing the hierarchical structure of the whole text but also determining which items of information are central to the meaning of the text and which are secondary propositions. Creating a discourse structure also includes the ability to recognize significance of different parts of the text to the writer or reader [Weir, 2003, p. 6].
Modern Russian Language Tests
The inventory of extant Russian language tests for native speakers includes the following: (1) VPR (All-Russia testing paper) which are end-of-year or promotion examinations, (2) OGE (Compulsory National Exam) enabling examinees “to obtain entrance to secondary education, either along a general university-preparatory track or a vocational-technical track” [Education in …, 2017]; and (3) EGE (National Unified Examination) functioning “as a final graduation examination, as well as an entrance examination for higher education” [Education in …, 2017]. Below, we describe the strengths and weaknesses of these assessments.
 (1)VPR (All-Russia testing paper), Grades 4-6.
The All-Russian testing papers (VPR) are mandatory tests aimed at “identifying students’ proficiency to meet the requirements of Federal (Russian) Educational Standard. VPRs are held to measure subject and meta-subject knowledge, universal learning skills and cross-curriculum concepts” [Opisanie kontrol'nyh …, 2019].
The writing part of Grade 4 VPR in the Russian language consists of two sections: Part I is a dictation and 2 follow-up items, Part II comprises 12 items, 9 of which are text-based tasks. Multiple choice questions are not used in VPR. The tasks of parts 1 and 2 are performed on different days. Each of the parts lasts 45 minutes. The structure and the procedure of the test are similar in VPR5 and VPR6.
As specified by the test designers, the VPR assesses the following: 
“3. Reading skills: 
3.1 Text comprehension. Reading for specific information. 
3.2 Reading for specific explicit information. 
3.3 Drawing simple conclusions based on the information in the text. 
3.4 Interpretation and synthesis of the information in the text. 
3.5 Analysis and assessment of the content, language features and text structure. 
4. Writing skills:  
4.1 Writing letters, combinations of letters, syllables, words, sentences as part of literacy training. 
4.2 Mastering neat writing. 
4.3 Copying, dictation. 
4.4 Reproducing a text (detailed, selective). 
4.5 Writing short original texts (essays) on topics interesting for children (based on impressions, literary works, pictures, series of pictures, video recording, etc.) [Opisanie kontrol'nyh …, 2019]. 
Closer inspection of these tests (VPR 4, VPR5, VPR 6) indicate that they predominantly assess students’ knowledge of language facts rather than comprehension skills. For example, in Part I VPR 4 students are expected to write a one-page dictation read by an examiner (item 1), identify sentences with similar predicates and underline them, copy those sentences and underline predicates (item 2); copy sentence 6 from Dictation, underline and define parts of speech of the subject and predicate (item 3).  The two first items in Part 2 assess students’ knowledge on orthoepic norms: mark the accent (stress) in the following 4 words (item 4); read the sentence below and copy the word with voiced consonants only (item 5). In items 6 – 8 students are asked to read a 150 word informational text with elements of narration followed by three open-ended type questions: identify and write down the main idea of the text (item 6); make a 3-point plan of the text and write it down (item 7); write down a question for your classmates which would test how well they comprehended the text above (item 8). Items 9-15 assess students’ vocabulary and grammar: define the meaning of the word ‘capital’ in Sentence 9 (item 9); change the word ‘known’ in Sentence 3 for the word with the same meaning (item 10); find a word in Sentence 1 which has the following morphological parts (which are coded with the accepted in the Russian tradition nomenclature as  ^□ ) (item 11); copy all nouns from sentence 7, define gender, declination, case, number of one of the nouns (item 12); copy all adjectives with the nouns they modify from Sentence 1, define gender, declination, case, number of one of the nouns (item 13); copy all verbs from sentence 3 (item 14); describe a life situation in which you can use the proverb ‘He who likes skiing downhill must enjoy climbing uphill’ (item 15). The proverb is not used in the text provided above. Thus, of the 15 items, only items 6 - 8 are testing participants’ comprehension skills. Further, these items are open-ended, which means that they are more time and resource-intensive, making it difficult use this assessment for rapid evaluation (See Tables 1, 4). 
(2) Compulsory (or Basic) National Exam (OGE) in Russian is a key element of the Russian system of assessing the quality of education. OGE scores are used to determine if students will have the opportunity to be enrolled in colleges (institutions of secondary vocational education) or proceed to high school. The test lasts 235 minutes.
The writing portion consists of three sections: Part 1 is a written account of a text, Part 2 (items 1-14) includes the following tasks: mark one of the four sentences below which provides an explanation to the question … (item 2); mark a sentences with a metaphor (item 3), in sentences 1 - 7 find a word with the prefix meaning “approaching”(item 4); in sentences 14 - 16 find a word with the suffix the spelling of which is an exception (item 5); find a neutral synonym for “whisper in the corner” (item 6); substitute the phrase “wooden box”, based on agreement between the adjective and the noun, with a phrase the components of which are connected with governance (item 7); find and copy the clause in sentence 22 (item 8); of sentences 22-24 find one in which unattached attributes are used (item 9); mark the only parenthetical word in the list of below (item 10); how many clauses are there in Sentence 51 (item 11); make a list of clauses from the compound sentences below (item 12); in sentences 1 – 6 find sentences with similar subordinate clauses (item 13); in sentences 44 – 53 find one with an asyndetic and coordinating relations (item 14); Part 3: Essay (item 15). 
The OGE mostly assesses students’ abilities in lexical access and syntactic parsing. The ‘inferencing’ and ‘building mental model’ items (items 1 and 15) that examine reading comprehension are open-ended questions requiring experts’ examination and assessment of student responses. [Demoversii, specifikacii …, 2019] (See Tables 2, 4).
(3) EGE (National Unified Examination or Uniform State Exam) in Russian 
The EGE is compulsory for high school graduates to complete secondary education and receive a School Leaving Certificate (Attestat o Srednem (Polnom) Obshchem Obrasovanii). It is a standardized test released uniformly throughout the Russian Federation and rated by independent raters. 
EGE in Russian is designed to measure proficiency in Russian regardless of how, when, and how well it has been taught. Thus, the exam has a broad proficiency orientation and its content is not supposed to be tied to any particular language-training program. The Construct of EGE 2019 in Russian defined in “Specification of Assessment Materials” includes 27 items and the following areas: 1. Speech. Text (5 test items). 2. Vocabulary and phraseology (2 items). 3. Speech. Spelling standards (7 items). 4. Speech. Punctuation norms (6 items). 5. Speech. Language norms (5 items). 6. The expressiveness of Russian speech (1 item). 7. The development of speech. Composition (1 item) ( See the complete construct of EGE in Table 6). The test is long and takes 210 min [FIPI: official …, 2019] (see the Specifications in Table 3, 4).
There are two limitations to using these existing assessments. The first is practical – the length of these exams renders them inefficient and uneconomical as a short “screening” tool. The second is more theoretically-oriented. While these tests evaluate important aspects of the Russian language, they do not focus on the higher-order comprehension skills that drive reading comprehension. These gaps drive our object to design a Russian Language test  that is reliable, valid, feasible, and economical.
Developing the Russian Language Test (RLT)
Stages of the Russian Language Test Developing included the following: (1) determining the purpose of the test, (2) designing test specifications, (3) constructing test items, (4) evaluating and revising test items, (5) specifying scoring procedures, and (6) performing validity (content, construct, and concurrent) and reliability. 
The purpose of the Russian language tests is to evaluate students’ Russian language ability and their preparedness to comprehend grade-appropriate content. RLT5 and RLT9 are designed to promptly assess learners’ proficiency for both lower-level skills, such as spelling, and higher-level skills, such as identification of a text’s genre.
The test constructs in RTL5 and RTL9 were defined based on the content and participants’ performance [Sigott, 2004].  The development of test content was driven by two postulates. The first is that vocabulary tests and C-tests are valid predictors of reading skills and general language proficiency [Harsch, 2016, p. 556; Alderson, 2005]. Both are viewed as being robust for placement and screening purposes [Harsch & Milton, 2009; Schröder et al., 2007]. The second is that Russian is a syntactically complex language, which requires readers to determine, and even change the gender of a noun or the punctuation of a sentence depending on the context. Thus, one of the major aspects of basic comprehension in Russian is the ability to make a number of grammatical inferences. 
With these factors in mind, we developed two grade-appropriate Russian language tests, for 5th grade and for 9th grade students. Two grade appropriate difficulty levels were developed to examine language proficiency at different points in development and to serve as future prototypes of a non-leveled Russian language test taken as IELTS regardless of participants’ period of schooling. 
To evaluate test validity, we used grade-appropriate texts [Ivanov et al, 2018].  We identified appropriate texts by calculating the Flesh-Kincaid Grade level (FKGL). This formula, modified for the Russian language, is: FKGmod (ASL,ASW) =0.36 × ASL + 5.76 × ASW − 11.97. ASL is the average number of words per sentence, and ASW is the average number of syllables per word [Solovyev et all, 2018]. In the RT5, the texts’ FKGL ranged from 4.5 to 6.1. In the RT9, the FKGL ranged from 8.6 to 10.6. 
The Russian language test (both RTL5 and RTL9) has two parts. Part I focuses on linguistic range, grammar accuracy, and local comprehension at the levels of decoding (word recognition, lexical access, and syntactic parsing) as well as establishing propositional meaning at the sentence and clause level. Part II in both versions of the test consists of one item only and offers a global comprehension task in which participants are expected to identify macro-propositions and infer implicit information.
Students have 30 minutes to complete the RLT. Both RLTs are delivered on paper. The tests are administered in a group setting, typically with 20-25 participants in a classroom.
RLT5 and RLT9 comprise instructions on how to complete each item, examples on how to answer the questions, and the item sets. The text passages in RLTs are sampled from real-life sources such as fiction and mass media. Each item is formulated as an instruction (e.g., Mark the correct sentence, Fill in the blanks with the derivatives of the word provided, Define the idiom).
All the materials were reviewed from a variety of settings and piloted with more than 50 native speakers of Russian. An initial pilot test of 30 potential items reduced the number of tasks to 11 items for the 5th graders with and 13 items for the 9th graders (See Tables 6 and 7). 
The final version of RLT5 consists of 11 items and the RLT 9 comprises 13 items. The test items can be divided among lexical access, syntactic parsing, inferencing and building a mental model. Example items are shown in Table 5. 
Item difficulty is measured in terms of the proportion of wrong responses for every item of a given test [Farhady et al, 1994; Manual for …, 2011]. All questions in RLTs are scored analytically with three rubrics: true – score 1, 1 minor error – score 0.5, wrong – 0.
Initial Validation Study
Once the Russian Language Test was constructed and refined, it was important to conduct a more ecologically-valid test. There were three goals of the current study. The first was to identify overall strengths and weaknesses in students’ Russian proficiency skills. The second was to pilot this version of the test with Russian students. The third goal was to explore how performance on the RLT related to individual differences (e.g., gender, age, and general knowledge).
Participants
Participants were fifth-grade (n = 81) and ninth-grade (n = 94) students recruited from three high schools in Kazan, Russia, and two suburban schools in Saby, Tatarstan. The participation in the research was voluntary and the participants were informed that they were free to discontinue participation at any time. The participants’ parents were provided the information on the purpose, procedures, confidentiality of the data received. The data collection began after copies of consent forms from parents of all children were filed and the Ethics Committee of Kazan Federal University issued an approval to conduct the research in November 2018. The data were collected in November 2018 through February 2019 in Kazan and Saby, Russia.
Materials
The participants completed the grade-appropriate Russian Language Test and a general knowledge test. The 5th graders completed the Weschler Intelligence Scale for Children (WISC) and 9th graders completed the Weschler Adult Intelligence Scale (WAIS). Both versions of the test are based on the adapted for Russian-speaking respondents and standardized version of A.Yu. Panasyuk (1973) and Yu.I. Filimonenko (1994). The Russian version of WISC contains 27 close-ended questions and the WAIS modification of the General knowledge test comprises 29 close-ended questions. WISC and WAIS are scored by giving one point for each correct answer.
WISC and WAIS assess participants’ general knowledge rather than topic-specific or theoretical knowledge. The results of the tests provide an estimate of an individual’s strengths and weaknesses associated with working memory, processing speed, and long-term memory. We examined the degree to which scores on the WISC and WAIS were related to Russian language proficiency and reading comprehension.
Results
Overall Performance. We first examined overall performance on the RLT. Scores were sectioned into four bands: Band I corresponds to 0 – 3.5 (0 - 25 %) tasks completed correctly; Band II is correlated with 4 – 6 (26 - 50%) tasks rated correctly, Band III was assigned if the participants performed 6.5 – 8 (51 - 75%) items correctly, Band IV reflects students who received 8.5 - 11 out of 13 (76 - 100%). As shown in Figure 1 and Table 8, 5th graders demonstrated a relatively normal distribution, with most students scoring within Bands II and III, with fewer students scoring in the lowest and highest bands. Figure 2 and Table 9 show a similar distribution for the 9th graders. 
Item Analyses. To examine where students excelled and struggled, we analyzed participants’ performance on each item of the RLT (see Figure 1, Figure 2) and data on the proportion of students who correctly answered the questions of each item (Figure 3, Figure 4, Tables 6 - 7). Tables 6 and 7 show the proportion of students who answered each question correctly. The majority of the 5th grade students (85%) were able to accurately identify a correct conjunction. In contrast, only 11% of the 5th graders were able to accurately convert from active to passive (Table 6). The 9th graders had little trouble identifying the genre of a text (95%), but had difficulty with both items related to correcting finite and non-finite verbs (5.5% and 12.5%; Table 7). 
General Knowledge Tests. Tables 12 and 13 present performance on the Russian language and knowledge assessments as a function of gender. Fifth graders’ comprehension and WISC general knowledge scores did not differ as a function of gender (Table 12). In contrast, the ninth graders showed a gender effect for proficiency, such that females scored higher than males (Table 13).
The participants’ performance in RT5 presented in Figure 1 shows that all participants successfully managed the test demonstrating above average results. Scores on the Russian Language Test were moderately correlated with the respective general knowledge test scores for both 5th graders, r = .33, and 9th graders, r = .38 (Figures 3 and 4).
Discussion and Future Directions
This study tested the Russian Language Test, the first of its kind to assess students’ basic Russian skills (e.g., vocabulary knowledge, grammar). Consistent with Zuckerman et al. (2013), these findings suggest that Russian students may need support moving beyond recitation to deeper comprehension. This study further demonstrates that students are struggling to construct the necessary grammatical inferences that help to maintain coherence across the text. 
We are continuing to iteratively revise the test. One aim is to construct additional items that assess higher-order inferences motivated by traditional discourse theory and situation model building (Kintsch & van Dijk, 1978). We are also collecting more data to better understand how Russian Language Test performance relates to performance on other reading comprehension tasks. 
One cautionary note regarding the current study is raised due to the sample being limited to 11–12 year-olds and 15-16 year-olds from only two educational contexts (Kazan and Saby). Hence, further research is needed for other contexts and age groups. It will also be of value to investigate the feasibility and accuracy of the Russian Language Test in an online environment. A computerized version of the test would allow for evaluation in broader contexts without a high increase of administration costs and thus afford assessment at scale. 
Literacy is a crucial skill in today’s social and educational environments. It is crucial to both individual survival and a society’s success. Developing better language assessments helps to inform students’ instructional needs and where educators should focus their attention. Our objective is to improve our capacity to better understand Russian language students’ strengths and weaknesses across all ages. In turn, we hope to contribute to educators’ capacity to address students’ needs.  
